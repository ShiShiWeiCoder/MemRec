import subprocess
import re
import json
import os
import sys
import argparse
from datetime import datetime

def parse_args():
    """è§£æžå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è®­ç»ƒå¤šçº§è®°å¿†å¢žå¼ºRankæ¨¡åž‹')
    parser.add_argument('--dataset', type=str, default='mooc', choices=['mooc', 'coursera'],
                       help='æ•°æ®é›†é€‰æ‹©: mooc (ä¸­æ–‡) æˆ– coursera (è‹±æ–‡)')
    return parser.parse_args()

# è§£æžå‚æ•°
args = parse_args()
dataset_name = args.dataset

# åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤¹å’Œæ—¥å¿—æ–‡ä»¶
log_dir = 'logs'
if not os.path.exists(log_dir):
    os.makedirs(log_dir)
log_file = open(f'{log_dir}/run_rank_multilevel_memory_{dataset_name}.log', 'w', encoding='utf-8')

def log_print(*args, **kwargs):
    """åŒæ—¶è¾“å‡ºåˆ°æŽ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶"""
    print(*args, **kwargs)
    print(*args, **kwargs, file=log_file)
    log_file.flush()

# è®°å½•å¼€å§‹æ—¶é—´
log_print(f"å¤šçº§è®°å¿†å¢žå¼ºRankæ¨¡åž‹è®­ç»ƒå¼€å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
log_print(f"æ•°æ®é›†: {dataset_name.upper()}")
log_print("=" * 60)

# ---------------------------
# å¤šçº§è®°å¿†å¢žå¼ºè®­ç»ƒå‚æ•°
# ---------------------------
data_dir = f'data/{dataset_name}/proc_data'
# Rankç²—æŽ’è¯´æ˜Žï¼šæ•°æ®æ–‡ä»¶ä½¿ç”¨rank.train/testï¼Œä½†æ¨¡åž‹taskä½¿ç”¨'rerank'ï¼ˆRankå’ŒRerankæ¨¡åž‹é€»è¾‘ç›¸åŒï¼‰
task_name = 'rerank'  # æ¨¡åž‹taskå‚æ•°ï¼ˆRankç²—æŽ’å’ŒRerankç²¾æŽ’çš„æ¨¡åž‹å¤„ç†é€»è¾‘ç›¸åŒï¼‰

# æ ¹æ®æ•°æ®é›†é€‰æ‹©å¯¹åº”çš„BERTæ¨¡åž‹ï¼ˆç»Ÿä¸€ä½¿ç”¨bert-base-uncasedï¼‰
if dataset_name == 'mooc':
    aug_prefix = 'bert-base-uncased_avg_augment_multilevel_memory'  # è‹±æ–‡BERT (bert-base-uncased)
else:  # coursera
    aug_prefix = 'bert-base-uncased_avg_augment_multilevel_memory'  # è‹±æ–‡BERT (bert-base-uncased)

# æ£€æŸ¥å¢žå¼ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
hist_file = os.path.join(data_dir, f'{aug_prefix}.hist')
item_file = os.path.join(data_dir, f'{aug_prefix}.item')

if not (os.path.exists(hist_file) and os.path.exists(item_file)):
    log_print(f"âŒ é”™è¯¯: {aug_prefix} å¢žå¼ºæ–‡ä»¶ä¸å­˜åœ¨")
    log_print(f"   éœ€è¦çš„æ–‡ä»¶: {hist_file}")
    log_print(f"   éœ€è¦çš„æ–‡ä»¶: {item_file}")
    log_print("   è¯·å…ˆè¿è¡ŒçŸ¥è¯†ç¼–ç ç”Ÿæˆè¿™äº›æ–‡ä»¶")
    sys.exit(1)

log_print(f"âœ… ä½¿ç”¨å¤šçº§è®°å¿†å¢žå¼º: {aug_prefix}")

# åŸºç¡€è®­ç»ƒå‚æ•°
augment = True
epoch = 30
lr_sched = 'cosine'

# æ ¹æ®æ•°æ®é›†è®¾ç½®ä¸åŒçš„metric_scope
if dataset_name == 'mooc':
    metric_scope = '5,10,20'  # MOOC: Rankç²—æŽ’(50ä¸ªå€™é€‰)
else:
    metric_scope = '1,2,3'  # Coursera: ä½¿ç”¨é»˜è®¤æŒ‡æ ‡

# æ ¹æ®æ•°æ®é›†è°ƒæ•´æ­£åˆ™åŒ–å‚æ•°ï¼ˆCourseraä¸¥é‡è¿‡æ‹Ÿåˆï¼Œéœ€è¦è¶…å¼ºæ­£åˆ™åŒ–ï¼‰
if dataset_name == 'coursera':
    weight_decay = 5e-3  # Coursera: è¶…å¼ºL2æ­£åˆ™åŒ– (1e-3 â†’ 5e-3)
    batch_size_list = [256]  # Coursera: ä½¿ç”¨ä¸ŽåŸºçº¿ç›¸åŒçš„æ‰¹æ¬¡å¤§å°
    lr_list = ['5e-4']  # Coursera: åªç”¨ä½Žå­¦ä¹ çŽ‡,é¿å…1e-3è¿‡é«˜å¯¼è‡´è¿‡æ‹Ÿåˆ
    dropout = 0.4  # Coursera: æ›´å¼ºdropout (0.3 â†’ 0.4)
    convert_dropout = 0.3  # Coursera: æ›´å¼ºè½¬æ¢dropout (0.2 â†’ 0.3)
    patience = 3  # Coursera: é™ä½Žè€å¿ƒå€¼,æ›´æ—©åœæ­¢é˜²è¿‡æ‹Ÿåˆ (8 â†’ 3)
    log_print("ðŸ“Š Courseraè¶…å¼ºæ­£åˆ™åŒ–: wd=5e-3, dropout=0.4, lr=5e-4, patience=3")
else:  # mooc
    weight_decay = 0  # MOOC: åŽŸå§‹å‚æ•°ï¼ˆæ•°æ®é›†è¾ƒå¤§ï¼Œä¸æ˜“è¿‡æ‹Ÿåˆï¼‰
    batch_size_list = [256, 512]  # MOOC: åŽŸå§‹æ‰¹æ¬¡å¤§å°
    lr_list = ['5e-4', '1e-3']  # MOOC: åŽŸå§‹å­¦ä¹ çŽ‡
    dropout = 0.0  # MOOC: åŽŸå§‹dropout
    convert_dropout = 0.0  # MOOC: åŽŸå§‹è½¬æ¢å±‚dropout
    patience = 3  # MOOC: åŽŸå§‹æ—©åœè€å¿ƒ
    log_print("ðŸ“Š ä½¿ç”¨MOOCåŽŸå§‹å‚æ•°ï¼ˆé€‚åˆå¤§æ•°æ®é›†ï¼‰")

# å‚æ•°æœç´¢ç½‘æ ¼ï¼ˆæ ¹æ®æ•°æ®é›†å·²è®¾ç½®ï¼‰
# æ¨¡åž‹åˆ—è¡¨ï¼ˆæ‰€æœ‰CTRæ¨¡åž‹å‡å¯ç”¨äºŽRankï¼‰
model_list = ['DeepFM', 'xDeepFM', 'DCN', 'FiBiNet', 'FiGNN', 'AutoInt', 'DIN', 'DIEN']

# æ¨¡åž‹æž¶æž„å‚æ•°
embed_size = 32
final_mlp = '200,80'
convert_arch = '128,32'

# å¤šçº§è®°å¿†åˆ†ç¦»å‚æ•°ï¼ˆæ”¯æŒå¤šå¤´æ³¨æ„åŠ›èžåˆï¼‰
convert_type = 'MultilevelMemoryHEA'  # æ··åˆä¸“å®¶é€‚é…å™¨

# æ ¹æ®æ•°æ®é›†è°ƒæ•´æ¨¡åž‹å¤æ‚åº¦
if dataset_name == 'coursera':
    export_num = 1  # Coursera: å‡å°‘åŸºç¡€ä¸“å®¶æ•°é‡
    memory_specific_export_num = 2  # Coursera: å‡å°‘è®°å¿†ä¸“ç”¨ä¸“å®¶æ•°é‡
    memory_attn_heads = 2  # Coursera: å‡å°‘æ³¨æ„åŠ›å¤´æ•°
    enable_memory_attention = True
    # Courseraä¸ä½¿ç”¨é™ç»´,ä¿æŒåŽŸå§‹768ç»´
    enable_knowledge_reduction = False
    knowledge_reduction_dim = 768
    knowledge_reduction_dropout = 0.0
    log_print("ðŸ”§ ä½¿ç”¨ç®€åŒ–çš„å¤šçº§è®°å¿†æ¨¡å—ï¼ˆé€‚åˆå°æ•°æ®é›†ï¼‰")
    log_print("ðŸ”§ ä¿æŒåŽŸå§‹768ç»´BERTå‘é‡")
else:  # mooc
    export_num = 2  # MOOC: åŽŸå§‹åŸºç¡€ä¸“å®¶æ•°é‡
    memory_specific_export_num = 3  # MOOC: åŽŸå§‹è®°å¿†ä¸“ç”¨ä¸“å®¶æ•°é‡
    memory_attn_heads = 4  # MOOC: åŽŸå§‹æ³¨æ„åŠ›å¤´æ•°
    enable_memory_attention = True
    # MOOCæ•°æ®é›†ä¸ä½¿ç”¨é™ç»´
    enable_knowledge_reduction = False
    knowledge_reduction_dim = 768
    knowledge_reduction_dropout = 0.0
    log_print("ðŸ”§ ä½¿ç”¨å®Œæ•´çš„å¤šçº§è®°å¿†æ¨¡å—ï¼ˆé€‚åˆå¤§æ•°æ®é›†ï¼‰")

# è®­ç»ƒç»“æžœè®°å½•
results = []

# å¾ªçŽ¯è®­ç»ƒæ‰€æœ‰æ¨¡åž‹å’Œå‚æ•°ç»„åˆ
for model in model_list:
    log_print(f"\nðŸš€ å¼€å§‹è®­ç»ƒæ¨¡åž‹: {model}")
    log_print("-" * 50)
    
    for batch_size in batch_size_list:
        for lr in lr_list:
            log_print(f"\nðŸ“‹ å‚æ•°ç»„åˆ: æ‰¹æ¬¡={batch_size}, å­¦ä¹ çŽ‡={lr}")
            log_print(f"   ðŸ§  å¤šçº§è®°å¿†: æ„Ÿè§‰è®°å¿† + å·¥ä½œè®°å¿† + é•¿æœŸè®°å¿†")
            log_print(f"   ðŸ“Š è®°å¿†ä¸“å®¶æ•°: {memory_specific_export_num}")
            log_print(f"   ðŸŽ¯ å¤šå¤´æ³¨æ„åŠ›: {memory_attn_heads}å¤´èžåˆ")
            
            # æž„é€ è®­ç»ƒå‘½ä»¤ï¼ˆæ”¯æŒå¤šå¤´æ³¨æ„åŠ›èžåˆï¼‰
            cmd = ['python', '-u', 'RS/rank/main_rank_multilevel_memory.py',
                   f'--data_dir={data_dir}',
                   f'--augment={augment}',
                   f'--aug_prefix={aug_prefix}',
                   f'--task={task_name}',
                   f'--convert_arch={convert_arch}',
                   f'--convert_type={convert_type}',
                   f'--convert_dropout={convert_dropout}',
                   f'--epoch_num={epoch}',
                   f'--batch_size={batch_size}',
                   f'--lr={lr}',
                   f'--lr_sched={lr_sched}',
                   f'--weight_decay={weight_decay}',
                   f'--patience={patience}',
                   f'--algo={model}',
                   f'--embed_dim={embed_size}',
                   f'--export_num={export_num}',
                   f'--specific_export_num={memory_specific_export_num}',
                   f'--final_mlp_arch={final_mlp}',
                   f'--dropout={dropout}',
                   f'--metric_scope={metric_scope}',
                   # ðŸ§  å¤šçº§è®°å¿†æ ¸å¿ƒå‚æ•°ï¼ˆæ”¯æŒå¤šå¤´æ³¨æ„åŠ›ï¼‰
                   '--memory_mode=true',
                   f'--memory_fusion_type=attention',
                   f'--memory_specific_export_num={memory_specific_export_num}',
                   f'--memory_weight_decay=0.01',
                   # ðŸŽ¯ å¤šå¤´æ³¨æ„åŠ›èžåˆå‚æ•°
                   '--enable_memory_attention=true',
                   f'--memory_attn_heads={memory_attn_heads}',
                   # ðŸ”§ çŸ¥è¯†é™ç»´å‚æ•°
                   f'--enable_knowledge_reduction={enable_knowledge_reduction}',
                   f'--knowledge_reduction_dim={knowledge_reduction_dim}',
                   f'--knowledge_reduction_dropout={knowledge_reduction_dropout}'
                   ]
            
            log_print("æ‰§è¡Œå‘½ä»¤:", ' '.join(cmd))
            log_print("-" * 30)
            
            # è¿è¡Œè®­ç»ƒ
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            output_lines = []
            if process.stdout is not None:
                for line in process.stdout:
                    line = line.rstrip()
                    print(line)
                    print(line, file=log_file)
                    log_file.flush()
                    output_lines.append(line + '\n')
                
            process.wait()
            output = ''.join(output_lines)
            
            # æå–è®­ç»ƒç»“æžœ - åŠ¨æ€æå–metric_scopeä¸­æŒ‡å®šçš„Kå€¼
            metric_scope_list = [int(x.strip()) for x in metric_scope.split(',')]
            metrics_dict = {}
            for k in metric_scope_list:
                pattern = rf"@{k}, MAP: ([\d\.]+), NDCG: ([\d\.]+), HR: ([\d\.]+)"
                matches = re.findall(pattern, output)
                if matches:
                    # èŽ·å–æœ€åŽä¸€æ¬¡çš„ç»“æžœï¼ˆæœ€ç»ˆæµ‹è¯•ç»“æžœï¼‰
                    last_match = matches[-1]
                    metrics_dict[k] = {
                        'map': float(last_match[0]),
                        'ndcg': float(last_match[1]),
                        'hr': float(last_match[2])
                    }
            
            # æå–MRRï¼ˆå…¨å±€æŒ‡æ ‡ï¼Œæ— @Kï¼‰
            mrr_pattern = r"^MRR: ([\d\.]+)"
            mrr_matches = re.findall(mrr_pattern, output, re.MULTILINE)
            mrr_value = float(mrr_matches[-1]) if mrr_matches else None
            
            # æå–AUCï¼ˆå¦‚æžœæœ‰ï¼‰
            auc_pattern = r"^AUC: ([\d\.]+)"
            auc_matches = re.findall(auc_pattern, output, re.MULTILINE)
            auc_value = float(auc_matches[-1]) if auc_matches else None
            
            # è®°å½•ç»“æžœ
            # åŠ¨æ€èŽ·å–main_kä½œä¸ºä¸»è¦æŒ‡æ ‡
            main_k = metric_scope_list[len(metric_scope_list)//2] if metric_scope_list else 5
            
            result = {
                'model': model,
                'batch_size': batch_size,
                'lr': lr,
                'memory_experts': memory_specific_export_num,
                'attn_heads': memory_attn_heads,
                'metrics': metrics_dict,
                'map@5': metrics_dict.get(5, {}).get('map'),  # å‘åŽå…¼å®¹
                'ndcg@5': metrics_dict.get(5, {}).get('ndcg'),
                'hr@5': metrics_dict.get(5, {}).get('hr'),
                f'map@{main_k}': metrics_dict.get(main_k, {}).get('map'),  # åŠ¨æ€Kå€¼
                f'ndcg@{main_k}': metrics_dict.get(main_k, {}).get('ndcg'),
                f'hr@{main_k}': metrics_dict.get(main_k, {}).get('hr'),
                'mrr': mrr_value,  # MRRæ˜¯å…¨å±€æŒ‡æ ‡
                'auc': auc_value,
                'save_dir': save_dir
            }
            results.append(result)
            
            if metrics_dict:
                # åŠ¨æ€èŽ·å–metric_scopeä¸­çš„ä¸­é—´å€¼ä½œä¸ºä¸»è¦æŒ‡æ ‡æ˜¾ç¤º
                metric_scope_list = [int(x.strip()) for x in metric_scope.split(',')]
                main_k = metric_scope_list[len(metric_scope_list)//2] if metric_scope_list else 5
                
                if main_k in metrics_dict:
                    map_score = metrics_dict[main_k]['map']
                    ndcg_score = metrics_dict[main_k]['ndcg']
                    hr_score = metrics_dict[main_k]['hr']
                    log_print(f"âœ… å®Œæˆ: MAP@{main_k}={map_score:.5f}, NDCG@{main_k}={ndcg_score:.5f}, HR@{main_k}={hr_score:.5f}")
                    if mrr_value is not None:
                        log_print(f"   MRR={mrr_value:.5f}")
                    if auc_value is not None:
                        log_print(f"   AUC={auc_value:.5f}")
                else:
                    log_print(f"   âš ï¸  æŒ‡æ ‡@{main_k}ä¸å¯ç”¨")
            else:
                log_print(f"âŒ è®­ç»ƒå¤±è´¥æˆ–ç»“æžœè§£æžé”™è¯¯")
            log_print("=" * 30)

# è¾“å‡ºæœ€ç»ˆç»“æžœæ‘˜è¦
log_print(f"\nðŸ† å¤šçº§è®°å¿†å¢žå¼ºè®­ç»ƒç»“æžœæ‘˜è¦:")
log_print("=" * 70)

# åŠ¨æ€èŽ·å–ä¸»è¦Kå€¼
metric_scope_list = [int(x.strip()) for x in metric_scope.split(',')]
main_k = metric_scope_list[len(metric_scope_list)//2] if metric_scope_list else 5
map_key = f'map@{main_k}'
ndcg_key = f'ndcg@{main_k}'

# å…¼å®¹å¤„ç†ï¼šä¼˜å…ˆä½¿ç”¨@5ï¼Œå¦åˆ™ä½¿ç”¨main_k
valid_results = [r for r in results if r.get('map@5') is not None or r.get(map_key) is not None]
if valid_results:
    # æŒ‰MAPæŽ’åºï¼ˆä¼˜å…ˆä½¿ç”¨@5ï¼Œå¦åˆ™ä½¿ç”¨main_kï¼‰
    valid_results.sort(key=lambda x: x.get('map@5') or x.get(map_key, 0), reverse=True)
    
    log_print(f"ðŸ¥‡ Top 10 æœ€ä½³ç»“æžœ (æŒ‰MAP@{main_k}æŽ’åº):")
    for i, result in enumerate(valid_results[:10], 1):
        map_val = result.get('map@5') or result.get(map_key, 0)
        ndcg_val = result.get('ndcg@5') or result.get(ndcg_key, 0)
        log_print(f"{i:2d}. {result['model']:8s} | MAP@{main_k}={map_val:.5f} | "
                  f"æ‰¹æ¬¡={result['batch_size']:3d} | å­¦ä¹ çŽ‡={result['lr']} | "
                  f"è®°å¿†ä¸“å®¶={result['memory_experts']} | "
                  f"æ³¨æ„åŠ›å¤´={result['attn_heads']} | NDCG@{main_k}={ndcg_val:.5f}")
    
    # æ¯ä¸ªæ¨¡åž‹çš„æœ€ä½³ç»“æžœï¼ˆè¾“å‡ºå®Œæ•´æŒ‡æ ‡ï¼‰
    log_print(f"\nðŸ“Š å„æ¨¡åž‹æœ€ä½³æ€§èƒ½ (å®Œæ•´æŒ‡æ ‡):")
    log_print("-" * 70)
    for model in model_list:
        model_results = [r for r in valid_results if r['model'] == model]
        if model_results:
            best = model_results[0]  # å·²ç»æŒ‰MAPæŽ’åº
            log_print(f"\n{model}:")
            log_print(f"   å‚æ•°: æ‰¹æ¬¡={best['batch_size']}, å­¦ä¹ çŽ‡={best['lr']}, "
                     f"è®°å¿†ä¸“å®¶={best['memory_experts']}, æ³¨æ„åŠ›å¤´={best['attn_heads']}")
            
            # è¾“å‡ºå®Œæ•´çš„æŒ‡æ ‡ï¼ˆæ ¹æ®å®žé™…çš„metric_scopeï¼‰
            if 'metrics' in best and best['metrics']:
                for k in metric_scope_list:
                    if k in best['metrics']:
                        m = best['metrics'][k]
                        log_print(f"   @{k}: MAP={m['map']:.5f}, NDCG={m['ndcg']:.5f}, HR={m['hr']:.5f}")
            else:
                # å…¼å®¹æ—§æ•°æ®ï¼šæ˜¾ç¤º@5æˆ–main_k
                map_val = best.get('map@5') or best.get(map_key)
                ndcg_val = best.get('ndcg@5') or best.get(ndcg_key)
                hr_val = best.get('hr@5') or best.get(f'hr@{main_k}')
                if map_val is not None:
                    log_print(f"   MAP@{main_k}={map_val:.5f}, NDCG@{main_k}={ndcg_val:.5f}, HR@{main_k}={hr_val:.5f}")
            
            # MRRå’ŒAUCå•ç‹¬è¾“å‡ºï¼ˆå…¨å±€æŒ‡æ ‡ï¼‰
            if best.get('mrr') is not None:
                log_print(f"   MRR={best['mrr']:.5f}")
            if best.get('auc') is not None:
                log_print(f"   AUC={best['auc']:.5f}")
    
    # æ•´ä½“ç»Ÿè®¡
    maps = [r.get('map@5') or r.get(map_key, 0) for r in valid_results]
    avg_map = sum(maps) / len(maps)
    max_map = max(maps)
    min_map = min(maps)
    
    log_print(f"\nðŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
    log_print(f"   å¹³å‡MAP@{main_k}: {avg_map:.5f}")
    log_print(f"   æœ€é«˜MAP@{main_k}: {max_map:.5f}")
    log_print(f"   æœ€ä½ŽMAP@{main_k}: {min_map:.5f}")
    log_print(f"   æˆåŠŸè®­ç»ƒ: {len(valid_results)}/{len(results)} ç»„åˆ")

else:
    log_print("âŒ æ²¡æœ‰æˆåŠŸçš„è®­ç»ƒç»“æžœ")

# ä¿å­˜ç»“æžœåˆ°JSONæ–‡ä»¶
results_file = f'multilevel_memory_rank_training_results_{dataset_name}.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

log_print(f"\nðŸ’¾ ç»“æžœå·²ä¿å­˜åˆ°: {results_file}")
log_print(f"ðŸ å¤šçº§è®°å¿†å¢žå¼ºRankè®­ç»ƒå®Œæˆ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
log_print("=" * 60)

# è¾“å‡ºè®¤çŸ¥å¿ƒç†å­¦æ¡†æž¶è¯´æ˜Ž
log_print(f"\nðŸ§  è®¤çŸ¥å¿ƒç†å­¦å¤šçº§è®°å¿†æ¡†æž¶:")
log_print("=" * 50)
log_print("ðŸ”¥ æ„Ÿè§‰è®°å¿† (Sensory Memory):")
log_print("   - å³æ—¶éœ€æ±‚å’Œæœ€è¿‘æµè§ˆ (3-5æ¬¡äº¤äº’)")
log_print("   - æ•èŽ·ç”¨æˆ·çš„çž¬æ—¶å…´è¶£å’Œç›´è§‰ååº”")
log_print("")
log_print("âš¡ å·¥ä½œè®°å¿† (Working Memory):")
log_print("   - å½“å‰ä¼šè¯è¡Œä¸ºæ¨¡å¼ (10-15æ¬¡äº¤äº’)")
log_print("   - å¤„ç†æ­£åœ¨è¿›è¡Œçš„å­¦ä¹ ä»»åŠ¡")
log_print("")
log_print("ðŸ—ï¸ é•¿æœŸè®°å¿† (Long-Term Memory):")
log_print("   - èŒä¸šå‘å±•æ–¹å‘ (åŸºäºŽé¢†åŸŸåˆ†å¸ƒ)")
log_print("   - å­˜å‚¨ç§¯ç´¯çš„çŸ¥è¯†å’ŒæŠ€èƒ½")
log_print("=" * 50)

log_file.close()

# nohup python RS/rank/run_rank_multilevel_memory.py --dataset mooc > logs/rank_multilevel_memory.log 2>&1 &
